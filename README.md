# ğŸª´ IRIS-MLOPS-PIPELINE

An end-to-end **MLOps pipeline** for training, deploying, and serving an Iris flower classification model using **Docker**, **GitHub Actions**, and **Google Cloud Platform Kubernetes Engine (GKE)**.

---

## ğŸ“‚ Project Structure

```
sami-codeai-iris-mlops-pipeline/
â”œâ”€â”€ README.md                  # Project documentation
â”œâ”€â”€ application.py             # Flask app for model serving
â”œâ”€â”€ Dockerfile                 # Docker image configuration
â”œâ”€â”€ kubernetes-deployment.yaml # Kubernetes deployment specification
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ setup.py                   # Setup script (optional)
â”œâ”€â”€ artifacts/                 # Data & trained model artifacts
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ model.pkl          # Trained ML model
â”‚   â”œâ”€â”€ processed/             # Processed training/testing data
â”‚   â””â”€â”€ raw/
â”‚       â””â”€â”€ data.csv           # Raw Iris dataset
â”œâ”€â”€ notebook/
â”‚   â””â”€â”€ iris.ipynb             # Jupyter notebook for EDA & prototyping
â”œâ”€â”€ pipeline/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ training_pipeline.py   # Training pipeline code
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ custom_exception.py    # Custom exception handling
â”‚   â”œâ”€â”€ data_processing.py     # Data preprocessing scripts
â”‚   â”œâ”€â”€ logger.py              # Logging utility
â”‚   â””â”€â”€ model_training.py      # Model training logic
â”œâ”€â”€ static/
â”‚   â””â”€â”€ style.css              # Stylesheet for the web app
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html             # Frontend HTML template
â””â”€â”€ .github/
    â””â”€â”€ workflows/
        â””â”€â”€ deploy.yml         # CI/CD workflow configuration
```

---

## ğŸŒ¼ How It Works

**1ï¸âƒ£ Data Processing**
The Iris dataset (`artifacts/raw/data.csv`) is preprocessed by `data_processing.py` to handle splitting into training and testing sets. The processed files are saved in `artifacts/processed/`.

**2ï¸âƒ£ Model Training**
The `training_pipeline.py` uses the processed data to train a simple classification model (e.g., Logistic Regression, Decision Tree, etc.), which is saved as `model.pkl` in `artifacts/models/`.

**3ï¸âƒ£ Model Serving**
The `application.py` is a Flask web app that loads `model.pkl` and provides an interface (via `index.html`) to input flower measurements and receive predictions.

**4ï¸âƒ£ Containerization**
The application is containerized using the `Dockerfile`. It builds an image containing all necessary dependencies and exposes the Flask server.

**5ï¸âƒ£ Deployment on GKE**
The `kubernetes-deployment.yaml` defines the Kubernetes Deployment and Service for deploying the containerized app on Google Kubernetes Engine (GKE).

---

## ğŸš€ CI/CD Workflow

The pipeline uses **GitHub Actions** for Continuous Integration and Continuous Deployment:

âœ… **CI:**

* On every push or pull request:

  * Install dependencies (`requirements.txt`).
  * Run linting/tests (if added).
  * Build Docker image.
  * Run the container to check for runtime errors.

âœ… **CD:**

* If the build succeeds on `main`:

  * Authenticate with Google Cloud.
  * Build and push the Docker image to Google Container Registry (GCR).
  * Deploy/update the image on Google Kubernetes Engine using `kubectl` with `kubernetes-deployment.yaml`.

The entire workflow is defined in `.github/workflows/deploy.yml`.

---

## ğŸ“Œ How to Run Locally

1ï¸âƒ£ **Clone the Repo**

```bash
git clone https://github.com/<your-username>/sami-codeai-iris-mlops-pipeline.git
cd sami-codeai-iris-mlops-pipeline
```

2ï¸âƒ£ **Create Virtual Environment**

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3ï¸âƒ£ **Install Dependencies**

```bash
pip install -r requirements.txt
```

4ï¸âƒ£ **Run the Flask App**

```bash
python application.py
```

Visit `http://localhost:5000` in your browser.

---

## â˜ï¸ Deploy to GKE

1ï¸âƒ£ **Build Docker Image**

```bash
docker build -t iris-mlops-app .
```

2ï¸âƒ£ **Push to Google Container Registry**

```bash
docker tag iris-mlops-app gcr.io/<your-project-id>/iris-mlops-app
docker push gcr.io/<your-project-id>/iris-mlops-app
```

3ï¸âƒ£ **Deploy to Kubernetes**

```bash
kubectl apply -f kubernetes-deployment.yaml
kubectl get services
```


